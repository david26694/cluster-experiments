{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cluster Randomization Example\n",
        "\n",
        "This notebook demonstrates how to analyze a **cluster-randomized experiment** where randomization occurs at the group level (e.g., stores, cities, schools) rather than at the individual level.\n",
        "\n",
        "## Why Cluster Randomization?\n",
        "\n",
        "Cluster randomization is necessary when:\n",
        "\n",
        "1. **Spillover Effects**: Treatment of one individual affects others (e.g., testing driver incentives in ride-sharing)\n",
        "2. **Operational Constraints**: You can't randomize at the individual level (e.g., testing a store layout)\n",
        "3. **Cost Efficiency**: It's cheaper to randomize groups than individuals\n",
        "\n",
        "## Key Consideration\n",
        "\n",
        "With cluster randomization, you need to account for **intra-cluster correlation** - observations within the same cluster are more similar than observations from different clusters. This requires using **clustered standard errors** or cluster-level analysis methods.\n",
        "\n",
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from cluster_experiments import AnalysisPlan\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Simulate Cluster-Randomized Experiment\n",
        "\n",
        "Let's simulate an experiment where we test a promotional campaign across different stores. Each store is randomly assigned to control or treatment, and we observe multiple transactions per store.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define parameters\n",
        "n_stores = 50  # Number of stores (clusters)\n",
        "transactions_per_store = 100  # Average transactions per store\n",
        "\n",
        "# Step 1: Randomly assign stores to treatment\n",
        "stores = pd.DataFrame({\n",
        "    'store_id': range(n_stores),\n",
        "    'variant': np.random.choice(['control', 'treatment'], n_stores),\n",
        "})\n",
        "\n",
        "# Step 2: Generate transaction-level data\n",
        "transactions = []\n",
        "for _, store in stores.iterrows():\n",
        "    n_transactions = np.random.poisson(transactions_per_store)\n",
        "    \n",
        "    # Base purchase amount\n",
        "    base_amount = 50\n",
        "    \n",
        "    # Treatment effect: +$5 average purchase\n",
        "    treatment_effect = 5 if store['variant'] == 'treatment' else 0\n",
        "    \n",
        "    # Store-level random effect (intra-cluster correlation)\n",
        "    store_effect = np.random.normal(0, 10)\n",
        "    \n",
        "    # Generate transactions\n",
        "    store_transactions = pd.DataFrame({\n",
        "        'store_id': store['store_id'],\n",
        "        'variant': store['variant'],\n",
        "        'purchase_amount': np.random.normal(\n",
        "            base_amount + treatment_effect + store_effect, \n",
        "            20, \n",
        "            n_transactions\n",
        "        ).clip(min=0)  # No negative purchases\n",
        "    })\n",
        "    \n",
        "    transactions.append(store_transactions)\n",
        "\n",
        "data = pd.concat(transactions, ignore_index=True)\n",
        "\n",
        "print(f\"Total transactions: {len(data):,}\")\n",
        "print(f\"Stores in control: {(stores['variant'] == 'control').sum()}\")\n",
        "print(f\"Stores in treatment: {(stores['variant'] == 'treatment').sum()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Naive Analysis (WRONG!)\n",
        "\n",
        "First, let's see what happens if we ignore the clustering and use standard OLS. **This is wrong** because it doesn't account for intra-cluster correlation and will give you incorrect standard errors (typically too small, leading to false positives).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Naive analysis without clustering\n",
        "naive_plan = AnalysisPlan.from_metrics_dict({\n",
        "    'metrics': [\n",
        "        {\n",
        "            'alias': 'purchase_amount',\n",
        "            'name': 'purchase_amount',\n",
        "            'metric_type': 'simple'\n",
        "        },\n",
        "    ],\n",
        "    'variants': [\n",
        "        {'name': 'control', 'is_control': True},\n",
        "        {'name': 'treatment', 'is_control': False},\n",
        "    ],\n",
        "    'variant_col': 'variant',\n",
        "    'analysis_type': 'ols',  # Standard OLS (WRONG for clustered data!)\n",
        "})\n",
        "\n",
        "naive_results = naive_plan.analyze(data).to_dataframe()\n",
        "print(\"=== Naive Analysis (Ignoring Clusters) ===\")\n",
        "print(f\"Treatment Effect: ${naive_results.iloc[0]['ate']:.2f}\")\n",
        "print(f\"Standard Error: ${naive_results.iloc[0]['ate_se']:.2f}\")\n",
        "print(f\"P-value: {naive_results.iloc[0]['p_value']:.4f}\")\n",
        "print(f\"95% CI: [${naive_results.iloc[0]['ate_ci_lower']:.2f}, ${naive_results.iloc[0]['ate_ci_upper']:.2f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Correct Analysis with Clustered Standard Errors\n",
        "\n",
        "Now let's do the **correct** analysis by accounting for the clustering. We'll use `clustered_ols` which computes cluster-robust standard errors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correct analysis with clustered standard errors\n",
        "clustered_plan = AnalysisPlan.from_metrics_dict({\n",
        "    'metrics': [\n",
        "        {\n",
        "            'alias': 'purchase_amount',\n",
        "            'name': 'purchase_amount',\n",
        "            'metric_type': 'simple'\n",
        "        },\n",
        "    ],\n",
        "    'variants': [\n",
        "        {'name': 'control', 'is_control': True},\n",
        "        {'name': 'treatment', 'is_control': False},\n",
        "    ],\n",
        "    'variant_col': 'variant',\n",
        "    'analysis_type': 'clustered_ols',  # Clustered OLS (CORRECT!)\n",
        "    'analysis_config': {\n",
        "        'cluster_cols': ['store_id']  # Specify the clustering variable\n",
        "    }\n",
        "})\n",
        "\n",
        "clustered_results = clustered_plan.analyze(data).to_dataframe()\n",
        "print(\"=== Correct Analysis (With Clustering) ===\")\n",
        "print(f\"Treatment Effect: ${clustered_results.iloc[0]['ate']:.2f}\")\n",
        "print(f\"Standard Error: ${clustered_results.iloc[0]['ate_se']:.2f}\")\n",
        "print(f\"P-value: {clustered_results.iloc[0]['p_value']:.4f}\")\n",
        "print(f\"95% CI: [${clustered_results.iloc[0]['ate_ci_lower']:.2f}, ${clustered_results.iloc[0]['ate_ci_upper']:.2f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Compare Results\n",
        "\n",
        "Let's compare the two approaches side by side:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "comparison = pd.DataFrame({\n",
        "    'Method': ['Naive (OLS)', 'Correct (Clustered OLS)'],\n",
        "    'Treatment Effect': [\n",
        "        f\"${naive_results.iloc[0]['ate']:.2f}\",\n",
        "        f\"${clustered_results.iloc[0]['ate']:.2f}\"\n",
        "    ],\n",
        "    'Standard Error': [\n",
        "        f\"${naive_results.iloc[0]['ate_se']:.2f}\",\n",
        "        f\"${clustered_results.iloc[0]['ate_se']:.2f}\"\n",
        "    ],\n",
        "    'P-value': [\n",
        "        f\"{naive_results.iloc[0]['p_value']:.4f}\",\n",
        "        f\"{clustered_results.iloc[0]['p_value']:.4f}\"\n",
        "    ],\n",
        "    '95% CI': [\n",
        "        f\"[${naive_results.iloc[0]['ate_ci_lower']:.2f}, ${naive_results.iloc[0]['ate_ci_upper']:.2f}]\",\n",
        "        f\"[${clustered_results.iloc[0]['ate_ci_lower']:.2f}, ${clustered_results.iloc[0]['ate_ci_upper']:.2f}]\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\n=== Comparison ===\")\n",
        "print(comparison.to_string(index=False))\n",
        "print(\"\\nNotice: The clustered standard errors are LARGER, reflecting the\")\n",
        "print(\"additional uncertainty from intra-cluster correlation.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. **Always account for clustering** in your analysis when randomization happens at the cluster level\n",
        "2. **Clustered standard errors are typically larger** than naive standard errors\n",
        "3. **Ignoring clustering leads to overstated confidence** - you might claim significance when there isn't any\n",
        "4. **Use `clustered_ols` analysis type** and specify `cluster_cols` in the analysis config\n",
        "\n",
        "## When to Use Clustering\n",
        "\n",
        "Use clustered analysis when:\n",
        "- ✅ Randomization is at the group level (stores, cities, schools)\n",
        "- ✅ There are spillover effects between individuals\n",
        "- ✅ Observations within groups are more similar than across groups\n",
        "\n",
        "Don't use clustering when:\n",
        "- ❌ Randomization is truly at the individual level\n",
        "- ❌ There's no reason to believe observations are correlated within groups\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
