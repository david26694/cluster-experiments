{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cluster Randomization Example\n",
        "\n",
        "This notebook demonstrates how to analyze a **cluster-randomized experiment** where randomization occurs at the group level (e.g., stores, cities, schools) rather than at the individual level.\n",
        "\n",
        "## Why Cluster Randomization?\n",
        "\n",
        "Cluster randomization is necessary when:\n",
        "\n",
        "1. **Spillover Effects**: Treatment of one individual affects others (e.g., testing driver incentives in ride-sharing)\n",
        "2. **Operational Constraints**: You can't randomize at the individual level (e.g., testing a store layout)\n",
        "3. **Cost Efficiency**: It's cheaper to randomize groups than individuals\n",
        "\n",
        "## Key Consideration\n",
        "\n",
        "With cluster randomization, you need to account for **intra-cluster correlation** - observations within the same cluster are more similar than observations from different clusters. This requires using **clustered standard errors** or cluster-level analysis methods.\n",
        "\n",
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from cluster_experiments import AnalysisPlan\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Simulate Cluster-Randomized Experiment\n",
        "\n",
        "Let's simulate an experiment where we test a promotional campaign across different stores. Each store is randomly assigned to control or treatment, and we observe multiple transactions per store.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total transactions: 5,055\n",
            "Stores in control: 23\n",
            "Stores in treatment: 27\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>store_id</th>\n",
              "      <th>variant</th>\n",
              "      <th>purchase_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>control</td>\n",
              "      <td>83.479541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>control</td>\n",
              "      <td>78.039264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>control</td>\n",
              "      <td>65.286167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>control</td>\n",
              "      <td>63.589803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>control</td>\n",
              "      <td>94.543677</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   store_id  variant  purchase_amount\n",
              "0         0  control        83.479541\n",
              "1         0  control        78.039264\n",
              "2         0  control        65.286167\n",
              "3         0  control        63.589803\n",
              "4         0  control        94.543677"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define parameters\n",
        "n_stores = 50  # Number of stores (clusters)\n",
        "transactions_per_store = 100  # Average transactions per store\n",
        "\n",
        "# Step 1: Randomly assign stores to treatment\n",
        "stores = pd.DataFrame({\n",
        "    'store_id': range(n_stores),\n",
        "    'variant': np.random.choice(['control', 'treatment'], n_stores),\n",
        "})\n",
        "\n",
        "# Step 2: Generate transaction-level data\n",
        "transactions = []\n",
        "for _, store in stores.iterrows():\n",
        "    n_transactions = np.random.poisson(transactions_per_store)\n",
        "    \n",
        "    # Base purchase amount\n",
        "    base_amount = 50\n",
        "    \n",
        "    # Treatment effect: +$5 average purchase\n",
        "    treatment_effect = 5 if store['variant'] == 'treatment' else 0\n",
        "    \n",
        "    # Store-level random effect (intra-cluster correlation)\n",
        "    store_effect = np.random.normal(0, 10)\n",
        "    \n",
        "    # Generate transactions\n",
        "    store_transactions = pd.DataFrame({\n",
        "        'store_id': store['store_id'],\n",
        "        'variant': store['variant'],\n",
        "        'purchase_amount': np.random.normal(\n",
        "            base_amount + treatment_effect + store_effect, \n",
        "            20, \n",
        "            n_transactions\n",
        "        ).clip(min=0)  # No negative purchases\n",
        "    })\n",
        "    \n",
        "    transactions.append(store_transactions)\n",
        "\n",
        "data = pd.concat(transactions, ignore_index=True)\n",
        "\n",
        "print(f\"Total transactions: {len(data):,}\")\n",
        "print(f\"Stores in control: {(stores['variant'] == 'control').sum()}\")\n",
        "print(f\"Stores in treatment: {(stores['variant'] == 'treatment').sum()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Naive Analysis (WRONG!)\n",
        "\n",
        "First, let's see what happens if we ignore the clustering and use standard OLS. **This is wrong** because it doesn't account for intra-cluster correlation and will give you incorrect standard errors (typically too small, leading to false positives).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Naive Analysis (Ignoring Clusters) ===\n",
            "Treatment Effect: $4.26\n",
            "Standard Error: $0.63\n",
            "P-value: 0.0000\n",
            "95% CI: [$3.03, $5.48]\n"
          ]
        }
      ],
      "source": [
        "# Naive analysis without clustering\n",
        "naive_plan = AnalysisPlan.from_metrics_dict({\n",
        "    'metrics': [\n",
        "        {\n",
        "            'alias': 'purchase_amount',\n",
        "            'name': 'purchase_amount',\n",
        "            'metric_type': 'simple'\n",
        "        },\n",
        "    ],\n",
        "    'variants': [\n",
        "        {'name': 'control', 'is_control': True},\n",
        "        {'name': 'treatment', 'is_control': False},\n",
        "    ],\n",
        "    'variant_col': 'variant',\n",
        "    'analysis_type': 'ols',  # Standard OLS (WRONG for clustered data!)\n",
        "})\n",
        "\n",
        "naive_results = naive_plan.analyze(data).to_dataframe()\n",
        "print(\"=== Naive Analysis (Ignoring Clusters) ===\")\n",
        "print(f\"Treatment Effect: ${naive_results.iloc[0]['ate']:.2f}\")\n",
        "print(f\"Standard Error: ${naive_results.iloc[0]['std_error']:.2f}\")\n",
        "print(f\"P-value: {naive_results.iloc[0]['p_value']:.4f}\")\n",
        "print(f\"95% CI: [${naive_results.iloc[0]['ate_ci_lower']:.2f}, ${naive_results.iloc[0]['ate_ci_upper']:.2f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Correct Analysis with Clustered Standard Errors\n",
        "\n",
        "Now let's do the **correct** analysis by accounting for the clustering. We'll use `clustered_ols` which computes cluster-robust standard errors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Correct Analysis (With Clustering) ===\n",
            "Treatment Effect: $4.26\n",
            "Standard Error: $3.04\n",
            "P-value: 0.1610\n",
            "95% CI: [$-1.70, $10.21]\n"
          ]
        }
      ],
      "source": [
        "# Correct analysis with clustered standard errors\n",
        "clustered_plan = AnalysisPlan.from_metrics_dict({\n",
        "    'metrics': [\n",
        "        {\n",
        "            'alias': 'purchase_amount',\n",
        "            'name': 'purchase_amount',\n",
        "            'metric_type': 'simple'\n",
        "        },\n",
        "    ],\n",
        "    'variants': [\n",
        "        {'name': 'control', 'is_control': True},\n",
        "        {'name': 'treatment', 'is_control': False},\n",
        "    ],\n",
        "    'variant_col': 'variant',\n",
        "    'analysis_type': 'clustered_ols',  # Clustered OLS (CORRECT!)\n",
        "    'analysis_config': {\n",
        "        'cluster_cols': ['store_id']  # Specify the clustering variable\n",
        "    }\n",
        "})\n",
        "\n",
        "clustered_results = clustered_plan.analyze(data).to_dataframe()\n",
        "print(\"=== Correct Analysis (With Clustering) ===\")\n",
        "print(f\"Treatment Effect: ${clustered_results.iloc[0]['ate']:.2f}\")\n",
        "print(f\"Standard Error: ${clustered_results.iloc[0]['std_error']:.2f}\")\n",
        "print(f\"P-value: {clustered_results.iloc[0]['p_value']:.4f}\")\n",
        "print(f\"95% CI: [${clustered_results.iloc[0]['ate_ci_lower']:.2f}, ${clustered_results.iloc[0]['ate_ci_upper']:.2f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Compare Results\n",
        "\n",
        "Let's compare the two approaches side by side:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Comparison ===\n",
            "                 Method Treatment Effect Standard Error P-value           95% CI\n",
            "            Naive (OLS)            $4.26          $0.63  0.0000   [$3.03, $5.48]\n",
            "Correct (Clustered OLS)            $4.26          $3.04  0.1610 [$-1.70, $10.21]\n",
            "\n",
            "Notice: The clustered standard errors are LARGER, reflecting the\n",
            "additional uncertainty from intra-cluster correlation.\n"
          ]
        }
      ],
      "source": [
        "comparison = pd.DataFrame({\n",
        "    'Method': ['Naive (OLS)', 'Correct (Clustered OLS)'],\n",
        "    'Treatment Effect': [\n",
        "        f\"${naive_results.iloc[0]['ate']:.2f}\",\n",
        "        f\"${clustered_results.iloc[0]['ate']:.2f}\"\n",
        "    ],\n",
        "    'Standard Error': [\n",
        "        f\"${naive_results.iloc[0]['std_error']:.2f}\",\n",
        "        f\"${clustered_results.iloc[0]['std_error']:.2f}\"\n",
        "    ],\n",
        "    'P-value': [\n",
        "        f\"{naive_results.iloc[0]['p_value']:.4f}\",\n",
        "        f\"{clustered_results.iloc[0]['p_value']:.4f}\"\n",
        "    ],\n",
        "    '95% CI': [\n",
        "        f\"[${naive_results.iloc[0]['ate_ci_lower']:.2f}, ${naive_results.iloc[0]['ate_ci_upper']:.2f}]\",\n",
        "        f\"[${clustered_results.iloc[0]['ate_ci_lower']:.2f}, ${clustered_results.iloc[0]['ate_ci_upper']:.2f}]\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\n=== Comparison ===\")\n",
        "print(comparison.to_string(index=False))\n",
        "print(\"\\nNotice: The clustered standard errors are LARGER, reflecting the\")\n",
        "print(\"additional uncertainty from intra-cluster correlation.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. **Always account for clustering** in your analysis when randomization happens at the cluster level\n",
        "2. **Clustered standard errors are typically larger** than naive standard errors\n",
        "3. **Ignoring clustering leads to overstated confidence** - you might claim significance when there isn't any\n",
        "4. **Use `clustered_ols` analysis type** and specify `cluster_cols` in the analysis config\n",
        "\n",
        "## When to Use Clustering\n",
        "\n",
        "Use clustered analysis when:\n",
        "- ✅ Randomization is at the group level (stores, cities, schools)\n",
        "- ✅ There are spillover effects between individuals\n",
        "- ✅ Observations within groups are more similar than across groups\n",
        "\n",
        "Don't use clustering when:\n",
        "- ❌ Randomization is truly at the individual level\n",
        "- ❌ There's no reason to believe observations are correlated within groups\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
